<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Konverter.ai Voice</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0A0F2C 0%, #1A1B46 100%);
            color: white;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            overflow-x: hidden;
        }

        .chat-container {
            width: 100%;
            height: 100vh;
            background: rgba(10, 15, 44, 0.8);
            backdrop-filter: blur(20px);
            display: flex;
            flex-direction: column;
            position: relative;
        }

        .header {
            padding: 30px 20px 20px;
            text-align: center;
            position: relative;
            z-index: 10;
        }

        .logo {
            width: 60px;
            height: 60px;
            margin: 0 auto 15px;
            background: linear-gradient(135deg, #5B42F3 0%, #00DDEB 100%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 28px;
            box-shadow: 0 8px 32px rgba(91, 66, 243, 0.3);
        }

        .title {
            font-size: 24px;
            font-weight: 700;
            margin-bottom: 5px;
            background: linear-gradient(135deg, #5B42F3 0%, #00DDEB 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            letter-spacing: -0.5px;
        }

        .subtitle {
            font-size: 14px;
            font-weight: 400;
            opacity: 0.8;
            margin-bottom: 10px;
            letter-spacing: 0.2px;
        }

        .status {
            font-size: 14px;
            font-weight: 500;
            padding: 6px 16px;
            border-radius: 20px;
            display: inline-block;
            background: rgba(255, 255, 255, 0.1);
            margin-bottom: 10px;
        }

        .status.connected {
            background: rgba(46, 213, 115, 0.2);
            color: #2ed573;
        }

        .status.error {
            background: rgba(255, 107, 107, 0.2);
            color: #ff6b6b;
        }

        .status.recording {
            background: rgba(255, 167, 38, 0.2);
            color: #ffa726;
        }

        .conversation-area {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            display: flex;
            flex-direction: column;
            position: relative;
        }

        .conversation-log {
            flex: 1;
            overflow-y: auto;
            padding: 10px;
            margin-bottom: 20px;
            scrollbar-width: thin;
            scrollbar-color: rgba(255, 255, 255, 0.2) transparent;
        }

        .conversation-log::-webkit-scrollbar {
            width: 4px;
        }

        .conversation-log::-webkit-scrollbar-track {
            background: transparent;
        }

        .conversation-log::-webkit-scrollbar-thumb {
            background-color: rgba(255, 255, 255, 0.2);
            border-radius: 20px;
        }

        .message {
            margin-bottom: 16px;
            padding: 12px 16px;
            border-radius: 16px;
            max-width: 85%;
            word-wrap: break-word;
            position: relative;
            animation: fadeIn 0.3s ease-out;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            line-height: 1.5;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: linear-gradient(135deg, #5B42F3 0%, #4A36C4 100%);
            margin-left: auto;
            border-bottom-right-radius: 4px;
        }

        .message.ai {
            background: linear-gradient(135deg, #2C3E50 0%, #1A1B46 100%);
            margin-right: auto;
            border-bottom-left-radius: 4px;
        }

        .message-avatar {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            position: absolute;
            bottom: -10px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 12px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
        }

        .message.user .message-avatar {
            background: #5B42F3;
            right: -10px;
        }

        .message.ai .message-avatar {
            background: #00DDEB;
            left: -10px;
        }

        .controls-container {
            position: relative;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .waveform {
            width: 100%;
            height: 80px;
            border-radius: 20px;
            margin-bottom: 30px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
            background: rgba(255, 255, 255, 0.05);
            box-shadow: inset 0 2px 10px rgba(0, 0, 0, 0.2);
        }

        .wave-bar {
            width: 4px;
            background: rgba(91, 66, 243, 0.6);
            margin: 0 2px;
            border-radius: 4px;
            transition: height 0.1s ease;
        }

        .wave-bar:nth-child(odd) {
            background: rgba(0, 221, 235, 0.6);
        }

        .mic-button-container {
            position: relative;
            margin-bottom: 30px;
            display: flex;
            justify-content: center;
            width: 100%;
        }

        .mic-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #5B42F3 0%, #00DDEB 100%);
            color: white;
            font-size: 32px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 32px rgba(91, 66, 243, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 10;
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 12px 40px rgba(91, 66, 243, 0.4);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #FF4757, #FF6B6B);
            animation: pulse 1.5s ease-in-out infinite alternate;
            box-shadow: 0 8px 32px rgba(255, 71, 87, 0.3);
        }

        .mic-button.connected {
            background: linear-gradient(135deg, #5B42F3, #00DDEB);
        }

        .mic-button:disabled {
            background: #2C3E50;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
            opacity: 0.7;
        }

        @keyframes pulse {
            from { transform: scale(1); box-shadow: 0 8px 32px rgba(255, 71, 87, 0.3); }
            to { transform: scale(1.1); box-shadow: 0 12px 40px rgba(255, 71, 87, 0.5); }
        }

        .mic-button-ring {
            position: absolute;
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: 2px solid rgba(91, 66, 243, 0.3);
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 5;
        }

        .mic-button-ring.outer {
            width: 120px;
            height: 120px;
            border: 1px solid rgba(91, 66, 243, 0.2);
        }

        .mic-button.recording + .mic-button-ring {
            border-color: rgba(255, 71, 87, 0.3);
            animation: ring-pulse 2s ease-in-out infinite;
        }

        .mic-button.recording + .mic-button-ring + .mic-button-ring.outer {
            border-color: rgba(255, 71, 87, 0.2);
            animation: ring-pulse-delay 2s ease-in-out infinite;
        }

        @keyframes ring-pulse {
            0% { transform: translate(-50%, -50%) scale(1); opacity: 0.7; }
            50% { transform: translate(-50%, -50%) scale(1.1); opacity: 0.5; }
            100% { transform: translate(-50%, -50%) scale(1); opacity: 0.7; }
        }

        @keyframes ring-pulse-delay {
            0% { transform: translate(-50%, -50%) scale(1); opacity: 0.5; }
            50% { transform: translate(-50%, -50%) scale(1.2); opacity: 0.3; }
            100% { transform: translate(-50%, -50%) scale(1); opacity: 0.5; }
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            width: 100%;
        }

        .control-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 30px;
            background: rgba(91, 66, 243, 0.2);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 14px;
            font-weight: 500;
            letter-spacing: 0.5px;
            backdrop-filter: blur(5px);
        }

        .control-btn:hover {
            background: rgba(91, 66, 243, 0.3);
            transform: translateY(-2px);
        }

        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .particles {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            z-index: 1;
            pointer-events: none;
        }

        .particle {
            position: absolute;
            background: rgba(91, 66, 243, 0.2);
            border-radius: 50%;
            pointer-events: none;
        }

        .session-info {
            position: absolute;
            bottom: 10px;
            left: 10px;
            font-size: 10px;
            opacity: 0.5;
            z-index: 5;
        }

        /* Hidden debug info */
        .debug-info {
            display: none;
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="particles" id="particles"></div>
        
        <div class="header">
            <div class="logo">üéôÔ∏è</div>
            <h1 class="title">Konverter.ai Voice</h1>
            <p class="subtitle">Premium AI voice conversation</p>
            <div class="status" id="status">Initializing...</div>
        </div>
        
        <div class="conversation-area">
            <div class="conversation-log" id="conversationLog">
                <div class="message ai">
                    üëã Welcome to Konverter.ai Voice! I'm your premium AI voice assistant. Tap Connect to start our conversation.
                    <div class="message-avatar">K</div>
                </div>
            </div>
        </div>
        
        <div class="controls-container">
            <div class="waveform" id="waveform">
                <!-- Wave bars will be generated here -->
            </div>
            
            <div class="mic-button-container">
                <button class="mic-button" id="micButton" disabled>
                    üé§
                </button>
                <div class="mic-button-ring"></div>
                <div class="mic-button-ring outer"></div>
            </div>
            
            <div class="controls">
                <button class="control-btn" id="connectBtn" disabled>Connect</button>
                <button class="control-btn" id="disconnectBtn" disabled>Disconnect</button>
            </div>
        </div>
        
        <div class="session-info" id="sessionInfo">
            Session: Loading...
        </div>
        
        <div class="debug-info" id="debugInfo">
            Debug info will appear here...
        </div>
    </div>

    <script type="module" src="gemini_audio_chat_client.js?v=2<!-- Force_Updated_audio_client -->"></script>
    <!-- <script type="module">
        class GeminiNativeAudioChat {
            constructor() {
                this.sessionToken = null;
                this.geminiClient = null;
                this.liveSession = null;
                this.isRecording = false;
                this.isConnected = false;
                this.mediaRecorder = null;
                this.audioContext = null; // Used for mic visualization
                this.analyser = null;
                this.dataArray = null;
                this.animationId = null;
                this.responseQueue = [];
                this.audioChunks = [];
                this.playbackAudioContext = null; // Used for playing Gemini's audio

                // VAD properties
                this.vadSilenceThreshold = 0.01; // Normalized energy; adjust based on testing
                this.vadRequiredSilenceDuration = 1500; // ms of silence before triggering EOS
                this.vadEnergySmoothing = 0.1; // Smoothing factor for energy readings
                this.currentEnergy = 0.0;
                this.silenceStartTime = 0;
                this.vadMonitoringInterval = null;
                
                this.initializeUI();
                this.initializeSession();
            }

            initializeUI() {
                this.statusEl = document.getElementById('status');
                this.micButton = document.getElementById('micButton');
                this.connectBtn = document.getElementById('connectBtn');
                this.disconnectBtn = document.getElementById('disconnectBtn');
                this.conversationLog = document.getElementById('conversationLog');
                this.sessionInfo = document.getElementById('sessionInfo');
                this.waveform = document.getElementById('waveform');
                this.debugInfo = document.getElementById('debugInfo');

                // Event listeners
                this.micButton.addEventListener('click', () => this.toggleRecording());
                this.connectBtn.addEventListener('click', () => this.connectToWebSocket());
                this.disconnectBtn.addEventListener('click', () => this.disconnect());

                // Generate wave bars
                this.generateWaveBars();
            }

            generateWaveBars() {
                this.waveform.innerHTML = '';
                for (let i = 0; i < 50; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'wave-bar';
                    bar.style.height = '10px';
                    this.waveform.appendChild(bar);
                }
            }

            addDebugInfo(message) {
                const timestamp = new Date().toLocaleTimeString();
                this.debugInfo.innerHTML += `${timestamp}: ${message}<br>`;
                this.debugInfo.scrollTop = this.debugInfo.scrollHeight;
                console.log(message);
            }

            async initializeSession() {
                try {
                    this.addDebugInfo('Starting session initialization...');
                    
                    // Get session token from URL
                    const urlParams = new URLSearchParams(window.location.search);
                    this.sessionToken = urlParams.get('session');
                    
                    if (!this.sessionToken) {
                        throw new Error('No session token provided');
                    }

                    this.addDebugInfo(`Session token: ${this.sessionToken.substring(0, 20)}...`);
                    this.updateStatus('Getting session config...');
                    
                    // Get session configuration from n8n
                    const apiUrl = `https://n8n.lomeai.com/webhook/voice-session?session=${this.sessionToken}&action=initialize`;
                    this.addDebugInfo(`Calling API: ${apiUrl}`);
                    
                    const response = await fetch(apiUrl);
                    const rawData = await response.json();
                    
                    this.addDebugInfo(`Raw response: ${JSON.stringify(rawData).substring(0, 200)}...`);
                    
                    // Handle the response format from n8n
                    let data;
                    if (Array.isArray(rawData) && rawData.length > 0) {
                        data = rawData[0];
                        this.addDebugInfo('Parsed array response');
                    } else {
                        data = rawData;
                        this.addDebugInfo('Direct response format');
                    }
                    
                    if (!data || !data.success) {
                        throw new Error(data?.error || 'Failed to initialize session');
                    }

                    this.sessionConfig = data.config;
                    this.sessionInfo.textContent = `Session: ${data.sessionId} | User: ${data.userId}`;
                    
                    this.addDebugInfo(`Model: ${this.sessionConfig.model}`);
                    this.addDebugInfo(`API Key: ${this.sessionConfig.apiKey ? 'Present' : 'Missing'}`);
                    
                    this.updateStatus('Ready to connect');
                    this.connectBtn.disabled = false;
                    
                } catch (error) {
                    this.addDebugInfo(`Session init error: ${error.message}`);
                    console.error('Session initialization failed:', error);
                    this.updateStatus('Failed to initialize session: ' + error.message, 'error');
                }
            }

            async connectToWebSocket() {
                try {
                    this.addDebugInfo('Connecting to WebSocket proxy...');
                    
                    // Get the WebSocket URL from the session config
                    const wsUrl = this.sessionConfig.websocketProxyUrl;
                    if (!wsUrl) {
                        throw new Error('No WebSocket proxy URL provided');
                    }
                    
                    // Create WebSocket connection with session token
                    this.ws = new WebSocket(`${wsUrl}&session=${this.sessionToken}`);
                    
                    // Set up WebSocket handlers
                    this.ws.onopen = () => {
                        this.addDebugInfo('WebSocket connection opened');
                        this.updateStatus('WebSocket connected, waiting for session initialization...', '');
                        
                        // Don't send connect_gemini here - wait for session_initialized message
                    };
                    
                    this.ws.onmessage = (event) => {
                        try {
                            const message = JSON.parse(event.data);
                            this.handleWebSocketMessage(message);
                        } catch (error) {
                            this.addDebugInfo(`Failed to parse message: ${error.message}`);
                        }
                    };
                    
                    this.ws.onerror = (error) => {
                        this.addDebugInfo(`WebSocket error: ${error.message}`);
                        this.updateStatus('Connection error', 'error');
                        this.handleDisconnection();
                    };
                    
                    this.ws.onclose = (event) => {
                        this.addDebugInfo(`WebSocket closed: ${event.reason}`);
                        this.updateStatus('Connection closed', 'error');
                        this.handleDisconnection();
                    };
                    
                } catch (error) {
                    this.addDebugInfo(`Connection error: ${error.message}`);
                    console.error('Failed to connect:', error);
                    this.updateStatus('Connection failed: ' + error.message, 'error');
                    this.connectBtn.disabled = false;
                }
            }

            handleWebSocketMessage(message) {
                switch (message.type) {
                    case 'session_initialized':
                        this.addDebugInfo('Session initialized successfully');
                        this.updateStatus('Session ready - Connecting to Gemini...', '');
                        
                        // Now it's safe to connect to Gemini
                        this.ws.send(JSON.stringify({
                            type: 'connect_gemini'
                        }));
                        this.addDebugInfo('Sent connect_gemini message');
                        break;
                        
                    case 'gemini_connected':
                        this.addDebugInfo('Received gemini_connected message');
                        this.isConnected = true;
                        this.updateStatus('Connected! Click microphone to talk', 'connected');
                        this.micButton.disabled = false;
                        this.micButton.classList.add('connected');
                        this.disconnectBtn.disabled = false;
                        this.connectBtn.disabled = true;
                        this.addMessage('ü§ñ Connected! I can hear you now. Click the microphone to start talking!', 'ai');
                        break;
                        
                    case 'gemini_disconnected':
                        this.addDebugInfo('Received gemini_disconnected message: ' + message.reason);
                        this.isConnected = false;
                        this.updateStatus('Disconnected from Gemini: ' + message.reason, 'error');
                        this.micButton.disabled = true;
                        this.micButton.classList.remove('connected');
                        this.disconnectBtn.disabled = true;
                        this.connectBtn.disabled = false;
                        this.addMessage('üîå Disconnected from Gemini: ' + message.reason, 'ai');
                        break;
                        
                    case 'audio_response':
                        this.playAudioResponse(message.audioData);
                        break;
                        
                    case 'text_response':
                        this.addMessage('ü§ñ ' + message.text, 'ai');
                        break;
                        
                    case 'error':
                        this.addDebugInfo(`Server error: ${message.message}`);
                        this.updateStatus(message.message, 'error');
                        break;
                        
                    case 'turn_complete':
                        this.addDebugInfo('Turn completed');
                        break;
                    
                    case 'gemini_setup_complete':
                        this.addDebugInfo('Received gemini_setup_complete message from backend.');
                        // You can add any UI updates here if needed when Gemini setup is fully complete.
                        break;

                    case 'input_transcription':
                        this.addDebugInfo(`Input transcription: ${message.text}`);
                        this.addMessage(`üé§ You (interim): ${message.text}`, 'user');
                        break;

                    case 'output_transcription':
                        this.addDebugInfo(`Output transcription: ${message.text}`);
                        this.addMessage(`ü§ñ AI (interim): ${message.text}`, 'ai');
                        break;
                        
                    default:
                        this.addDebugInfo(`Unknown message type: ${message.type}`);
                }
            }

            async sendAudioToServer(audioData, isEndOfSpeech = false) {
                if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    this.addDebugInfo('WebSocket not connected');
                    return;
                }

                try {
                    const messagePayload = {
                        type: 'audio_input',
                        audioData: audioData, // This is base64 encoded
                        mimeType: 'audio/webm;codecs=opus' // Correct MIME type for MediaRecorder default
                    };
                    if (isEndOfSpeech) {
                        messagePayload.isEndOfSpeech = true;
                    }
                    this.ws.send(JSON.stringify(messagePayload));
                    
                    this.addDebugInfo(`Audio sent: ${audioData ? audioData.length : 0} bytes, isEndOfSpeech: ${isEndOfSpeech}`);
                    
                } catch (error) {
                    this.addDebugInfo(`Failed to send audio: ${error.message}`);
                    console.error('Error sending audio:', error);
                }
            }

            async handleGeminiMessage(message) {
                // Handle different message types from Gemini Live API
                if (message.text) {
                    this.addMessage('ü§ñ ' + message.text, 'ai');
                    this.addDebugInfo(`Text response: ${message.text.substring(0, 50)}...`);
                }
                
                if (message.data) {
                    // Handle native audio response (24kHz PCM as per docs)
                    this.addDebugInfo(`Audio response received: ${message.data.length} bytes`);
                    await this.playAudioResponse(message.data);
                }
                
                if (message.serverContent) {
                    this.addDebugInfo('Server content received');
                    if (message.serverContent.turnComplete) {
                        this.addDebugInfo('Turn completed');
                    }
                }
            }

            async playAudioResponse(audioData) {
                try {
                    this.addDebugInfo(`Playing audio response. Data length (Base64): ${audioData ? audioData.length : 0}`);
                    if (!audioData) {
                        this.addDebugInfo('No audio data to play.');
                        return;
                    }

                    // Ensure we have an AudioContext for playback and it's running
                    if (!this.playbackAudioContext) {
                        try {
                            this.playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                            this.addDebugInfo(`Attempted to create playback AudioContext with 24000Hz. Actual rate: ${this.playbackAudioContext.sampleRate}Hz.`);
                            if (this.playbackAudioContext.sampleRate !== 24000) {
                                this.addDebugInfo(`Warning: Playback AudioContext running at ${this.playbackAudioContext.sampleRate}Hz, not desired 24000Hz. Playback speed issues may persist.`);
                            }
                        } catch (e) {
                            this.addDebugInfo(`Failed to create AudioContext with 24000Hz (${e.message}), falling back to default rate.`);
                            this.playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                            this.addDebugInfo(`Fallback playback AudioContext created with default rate: ${this.playbackAudioContext.sampleRate}Hz.`);
                        }
                    }
                    
                    if (this.playbackAudioContext.state === 'suspended') {
                        this.addDebugInfo('Playback AudioContext is suspended, attempting to resume...');
                        await this.playbackAudioContext.resume();
                        this.addDebugInfo(`Playback AudioContext state after resume: ${this.playbackAudioContext.state}`);
                    }
                    
                    const binaryString = window.atob(audioData);
                    const len = binaryString.length;
                    const bytes = new Uint8Array(len);
                    for (let i = 0; i < len; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    // For 24kHz, 16-bit, mono PCM audio from Gemini
                    const sampleRate = 24000;
                    const channels = 1;
                    const numSamples = bytes.length / 2; // 2 bytes per sample for 16-bit

                    if (numSamples === 0) {
                        this.addDebugInfo('Decoded audio data is empty (0 samples).');
                        return;
                    }
                    if (bytes.length % 2 !== 0) {
                        this.addDebugInfo(`Warning: Decoded audio data has an odd number of bytes (${bytes.length}), which is unusual for 16-bit PCM.`);
                        // Potentially truncate to the last full sample, though this indicates a problem upstream.
                    }

                    const audioBuffer = this.playbackAudioContext.createBuffer(channels, numSamples, sampleRate);
                    const channelData = audioBuffer.getChannelData(0);
                    
                    // Use DataView to read 16-bit signed PCM samples (little-endian)
                    // The underlying ArrayBuffer for `bytes` is `bytes.buffer`.
                    const dataView = new DataView(bytes.buffer, bytes.byteOffset, bytes.length);
                    for (let i = 0; i < numSamples; i++) {
                        const pcmSample = dataView.getInt16(i * 2, true); // true for little-endian
                        channelData[i] = pcmSample / 32768.0; // Normalize to [-1.0, 1.0]
                    }
                    
                    const source = this.playbackAudioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    
                    // Adjust playback rate to compensate for any mismatch between buffer's sample rate and context's sample rate
                    if (audioBuffer.sampleRate !== this.playbackAudioContext.sampleRate) {
                        const rateAdjustment = audioBuffer.sampleRate / this.playbackAudioContext.sampleRate;
                        source.playbackRate.value = rateAdjustment;
                        this.addDebugInfo(`Adjusting playback rate. Buffer SR: ${audioBuffer.sampleRate}, Context SR: ${this.playbackAudioContext.sampleRate}, Rate: ${rateAdjustment.toFixed(3)}`);
                    } else {
                        this.addDebugInfo(`Playback rate matches. Buffer SR: ${audioBuffer.sampleRate}, Context SR: ${this.playbackAudioContext.sampleRate}`);
                    }
                    
                    source.connect(this.playbackAudioContext.destination);
                    source.start();
                    
                    this.addMessage('üîä [Playing native audio response]', 'ai');
                    this.addDebugInfo(`Audio playback started. Buffer duration: ${audioBuffer.duration.toFixed(3)}s, Context SR: ${this.playbackAudioContext.sampleRate}Hz, Effective SR: ${audioBuffer.sampleRate / source.playbackRate.value}Hz`);
                    
                    source.onended = () => {
                        this.addDebugInfo('Audio playback finished.');
                        // It's good practice to disconnect the source node after it has finished playing.
                        try {
                            source.disconnect();
                        } catch (e) {
                            this.addDebugInfo(`Error disconnecting source: ${e.message}`);
                        }
                    };
                    
                } catch (error) {
                    this.addDebugInfo(`Audio playback error: ${error.message}. Stack: ${error.stack}`);
                    console.error('Error playing audio:', error);
                    this.addMessage('üîä [Received audio response - playback failed]', 'ai');
                }
            }

            async toggleRecording() {
                if (!this.isConnected) {
                    this.updateStatus('Please connect first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopRecording();
                } else {
                    await this.startContinuousConversation();
                }
            }

            async startContinuousConversation() {
                try {
                    this.addDebugInfo('Starting continuous conversation...');
                    
                    // Request microphone access with correct format for Gemini
                    // Input audio is natively 16kHz but API will resample as needed
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            channelCount: 1,
                            sampleRate: 16000,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        } 
                    });

                    this.addDebugInfo('Microphone access granted');

                    // Set up audio context for visualization
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);

                    this.analyser.fftSize = 256;
                    const bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(bufferLength);

                    // Start continuous recording for real-time streaming
                    this.stream = stream;
                    this.isRecording = true;
                    
                    this.micButton.classList.add('recording');
                    this.micButton.innerHTML = '‚èπÔ∏è';
                    this.updateStatus('Conversation active - Speak naturally', 'recording');
                    
                    this.startWaveAnimation();
                    this.addMessage('üé§ Continuous conversation started - speak naturally and Gemini will respond automatically', 'user');
                    
                    // Start streaming audio to Gemini in real-time
                    this.startContinuousAudioStreaming();
                    // Start VAD monitoring
                    this.startVADMonitoring();

                } catch (error) {
                    this.addDebugInfo(`Recording start error: ${error.message}`);
                    console.error('Failed to start recording:', error);
                    this.updateStatus('Microphone access denied: ' + error.message, 'error');
                }
            }

            async startContinuousAudioStreaming() {
                try {
                    // Create a media recorder for real-time streaming
                    this.mediaRecorder = new MediaRecorder(this.stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    this.audioChunks = [];
                    
                    this.mediaRecorder.ondataavailable = async (event) => {
                        if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                    // Send audio chunk to WebSocket server
                    const audioBuffer = await event.data.arrayBuffer();
                    const base64Audio = this.arrayBufferToBase64(audioBuffer);
                    // Send intermediate chunks with isEndOfSpeech: false
                    await this.sendAudioToServer(base64Audio, false);
                }
            };
            
            // Start recording with smaller time slices for more responsive streaming
            this.mediaRecorder.start(500); // 500ms chunks for better responsiveness
            
            this.addDebugInfo('Continuous audio streaming started with automatic VAD');
            
        } catch (error) {
            this.addDebugInfo(`Audio streaming error: ${error.message}`);
            console.error('Failed to start audio streaming:', error);
        }
    }

    stopRecording() {
        if (this.isRecording) {
            this.addDebugInfo('Stopping conversation (stopRecording called)...');
            this.stopVADMonitoring(); // Stop VAD first
            
            this.isRecording = false;
            
            if (this.mediaRecorder && this.mediaRecorder.state !== "inactive") {
                this.mediaRecorder.onstop = async () => {
                    this.addDebugInfo('MediaRecorder stopped, sending final isEndOfSpeech signal.');
                    await this.sendAudioToServer(null, true); 
                };
                try {
                    this.mediaRecorder.stop(); // This will trigger onstop
                } catch (e) {
                    this.addDebugInfo(`Error stopping mediaRecorder: ${e.message}. Still attempting to send EOS.`);
                    // If stop fails, still try to send EOS, though audio might be incomplete.
                    this.sendAudioToServer(null, true);
                }
            } else {
                this.addDebugInfo('MediaRecorder inactive or not found, sending isEndOfSpeech signal directly.');
                this.sendAudioToServer(null, true); // Send EOS if recorder wasn't active
            }
            
            if (this.stream) {
                this.stream.getTracks().forEach(track => track.stop());
                this.stream = null; // Clear the stream
            }
            
            if (this.audioContext && this.audioContext.state !== 'closed') {
                // No need to close the mic visualization audioContext here, 
                // as it's tied to the stream which is now stopped.
                // It will be recreated on next recording start.
            }
                    
            this.micButton.classList.remove('recording');
            this.micButton.innerHTML = 'üé§';
            this.updateStatus('Connected! Click microphone to start conversation', 'connected');
            
            this.stopWaveAnimation();
            this.addMessage('üé§ Conversation ended.', 'user');
        } else {
            this.addDebugInfo('stopRecording called but not currently recording.');
        }
    }

    startVADMonitoring() {
        this.stopVADMonitoring(); // Clear any existing interval
        this.silenceStartTime = 0;
        this.currentEnergy = 0.0;
        
        if (!this.analyser) {
            this.addDebugInfo("VAD: Analyser not ready, cannot start monitoring.");
            return;
        }
        this.addDebugInfo(`VAD: Starting monitoring. Threshold: ${this.vadSilenceThreshold}, Duration: ${this.vadRequiredSilenceDuration}ms`);
        
        this.vadMonitoringInterval = setInterval(() => this.checkVAD(), 100); // Check every 100ms
    }

    checkVAD() {
        if (!this.isRecording || !this.analyser || !this.dataArray) {
            // this.addDebugInfo("VAD: Not recording or analyser not ready.");
            return;
        }

        this.analyser.getByteFrequencyData(this.dataArray);
        let sum = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
            sum += this.dataArray[i];
        }
        const average = this.dataArray.length > 0 ? sum / this.dataArray.length : 0;
        
        const normalizedEnergy = average / 255; // Normalize to 0-1 range
        this.currentEnergy = (this.currentEnergy * (1 - this.vadEnergySmoothing)) + (normalizedEnergy * this.vadEnergySmoothing);

        // this.addDebugInfo(`VAD Energy: ${this.currentEnergy.toFixed(3)}`); // Optional: for debugging energy levels

        if (this.currentEnergy < this.vadSilenceThreshold) {
            if (this.silenceStartTime === 0) {
                this.silenceStartTime = Date.now();
                // this.addDebugInfo('VAD: Silence period started.');
            }
            
            if ((Date.now() - this.silenceStartTime) >= this.vadRequiredSilenceDuration) {
                this.addDebugInfo(`VAD: End of speech detected. Silence duration: ${Date.now() - this.silenceStartTime}ms`);
                this.stopVADMonitoring(); // Stop VAD before calling stopRecording
                this.stopRecording(); // This will handle sending EOS
            }
        } else {
            if (this.silenceStartTime !== 0) {
                // this.addDebugInfo('VAD: Speech detected, resetting silence timer.');
            }
            this.silenceStartTime = 0; // Reset silence timer if energy is above threshold
        }
    }

    stopVADMonitoring() {
        if (this.vadMonitoringInterval) {
            clearInterval(this.vadMonitoringInterval);
            this.vadMonitoringInterval = null;
            this.addDebugInfo("VAD: Monitoring stopped.");
        }
    }

    arrayBufferToBase64(buffer) {
                const bytes = new Uint8Array(buffer);
                let binary = '';
                for (let i = 0; i < bytes.byteLength; i++) {
                    binary += String.fromCharCode(bytes[i]);
                }
                return window.btoa(binary);
            }

            startWaveAnimation() {
                const animate = () => {
                    if (!this.isRecording) return;
                    
                    this.analyser.getByteFrequencyData(this.dataArray);
                    
                    const bars = this.waveform.querySelectorAll('.wave-bar');
                    bars.forEach((bar, index) => {
                        const value = this.dataArray[index] || 0;
                        const height = Math.max(5, (value / 255) * 50);
                        bar.style.height = height + 'px';
                    });
                    
                    this.animationId = requestAnimationFrame(animate);
                };
                animate();
            }

            stopWaveAnimation() {
                if (this.animationId) {
                    cancelAnimationFrame(this.animationId);
                    this.animationId = null;
                }
                
                const bars = this.waveform.querySelectorAll('.wave-bar');
                bars.forEach(bar => {
                    bar.style.height = '10px';
                });
            }

            disconnect() {
                this.addDebugInfo('Disconnecting...');
                if (this.ws) {
                    this.ws.close();
                }
                this.handleDisconnection();
            }

            handleDisconnection() {
                this.isConnected = false;
                this.isRecording = false;
                
                this.micButton.disabled = true;
                this.micButton.classList.remove('connected', 'recording');
                this.micButton.innerHTML = 'üé§';
                
                this.connectBtn.disabled = false;
                this.disconnectBtn.disabled = true;
                
                this.stopWaveAnimation();
                this.updateStatus('Disconnected. Click Connect to start again');
                
                if (this.stream) {
                    this.stream.getTracks().forEach(track => track.stop());
                }
            }

            updateStatus(message, type = '') {
                this.statusEl.textContent = message;
                this.statusEl.className = 'status ' + type;
            }

            addMessage(text, sender) {
                const messageEl = document.createElement('div');
                messageEl.className = `message ${sender}`;
                messageEl.textContent = text;
                
                // Add avatar to message
                const avatarEl = document.createElement('div');
                avatarEl.className = 'message-avatar';
                avatarEl.textContent = sender === 'ai' ? 'K' : 'U';
                messageEl.appendChild(avatarEl);
                
                this.conversationLog.appendChild(messageEl);
                this.conversationLog.scrollTop = this.conversationLog.scrollHeight;
                
                // Animate waveform when AI is speaking
                if (sender === 'ai' && text.includes('[Playing native audio response]')) {
                    this.animateWaveformForAudio();
                }
            }
            
            animateWaveformForAudio() {
                // Simulate audio waveform animation when AI is speaking
                let animationDuration = 0;
                const animate = () => {
                    if (animationDuration > 3000) return; // Stop after 3 seconds
                    
                    const bars = this.waveform.querySelectorAll('.wave-bar');
                    bars.forEach((bar) => {
                        const height = Math.max(5, Math.random() * 40);
                        bar.style.height = height + 'px';
                    });
                    
                    animationDuration += 100;
                    setTimeout(animate, 100);
                };
                animate();
            }
        }

        // Initialize the app when the page loads
        window.addEventListener('load', () => {
            new GeminiNativeAudioChat();
        });

        // Create animated particles
        class ParticleAnimation {
            constructor() {
                this.particles = [];
                this.container = document.getElementById('particles');
                this.containerWidth = this.container.clientWidth;
                this.containerHeight = this.container.clientHeight;
                
                this.createParticles();
                this.animate();
                
                // Handle resize
                window.addEventListener('resize', () => {
                    this.containerWidth = this.container.clientWidth;
                    this.containerHeight = this.container.clientHeight;
                });
            }
            
            createParticles() {
                // Clear existing particles
                this.container.innerHTML = '';
                this.particles = [];
                
                // Create new particles
                const particleCount = Math.min(50, Math.floor(this.containerWidth * this.containerHeight / 10000));
                
                for (let i = 0; i < particleCount; i++) {
                    const particle = document.createElement('div');
                    particle.className = 'particle';
                    
                    // Random properties
                    const size = Math.random() * 6 + 2;
                    const x = Math.random() * this.containerWidth;
                    const y = Math.random() * this.containerHeight;
                    const speedX = (Math.random() - 0.5) * 0.5;
                    const speedY = (Math.random() - 0.5) * 0.5;
                    const opacity = Math.random() * 0.3 + 0.1;
                    
                    // Set styles
                    particle.style.width = `${size}px`;
                    particle.style.height = `${size}px`;
                    particle.style.left = `${x}px`;
                    particle.style.top = `${y}px`;
                    particle.style.opacity = opacity;
                    
                    // Store particle data
                    this.particles.push({
                        element: particle,
                        x, y,
                        speedX, speedY,
                        size
                    });
                    
                    // Add to DOM
                    this.container.appendChild(particle);
                }
            }
            
            animate() {
                // Update particle positions
                this.particles.forEach(particle => {
                    // Update position
                    particle.x += particle.speedX;
                    particle.y += particle.speedY;
                    
                    // Boundary check
                    if (particle.x < -particle.size) particle.x = this.containerWidth;
                    if (particle.x > this.containerWidth) particle.x = -particle.size;
                    if (particle.y < -particle.size) particle.y = this.containerHeight;
                    if (particle.y > this.containerHeight) particle.y = -particle.size;
                    
                    // Update DOM
                    particle.element.style.left = `${particle.x}px`;
                    particle.element.style.top = `${particle.y}px`;
                });
                
                // Continue animation
                requestAnimationFrame(() => this.animate());
            }
        }

        // Telegram WebApp specific code
        if (window.Telegram?.WebApp) {
            window.Telegram.WebApp.ready();
            window.Telegram.WebApp.expand();
        }
        
// Initialize particle animation
window.addEventListener('load', () => {
    new ParticleAnimation();
});
    </script> -->
</body>
</html>
