<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Native Audio Chat</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <style>
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            overflow-x: hidden;
        }

        .chat-container {
            width: 100%;
            max-width: 400px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            text-align: center;
        }

        .logo {
            font-size: 48px;
            margin-bottom: 20px;
        }

        .title {
            font-size: 24px;
            font-weight: 600;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 16px;
            opacity: 0.8;
            margin-bottom: 30px;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            font-size: 48px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 30px rgba(0, 0, 0, 0.3);
        }

        .mic-button.recording {
            background: linear-gradient(45deg, #ff4757, #c44569);
            animation: pulse 1.5s ease-in-out infinite alternate;
        }

        .mic-button.connected {
            background: linear-gradient(45deg, #2ed573, #1e90ff);
        }

        .mic-button:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }

        @keyframes pulse {
            from { transform: scale(1); }
            to { transform: scale(1.1); }
        }

        .status {
            font-size: 16px;
            margin-bottom: 20px;
            min-height: 24px;
            font-weight: 500;
        }

        .status.connected {
            color: #2ed573;
        }

        .status.error {
            color: #ff6b6b;
        }

        .status.recording {
            color: #ffa726;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-top: 20px;
        }

        .control-btn {
            padding: 10px 20px;
            border: none;
            border-radius: 25px;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 14px;
        }

        .control-btn:hover {
            background: rgba(255, 255, 255, 0.3);
        }

        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .waveform {
            width: 100%;
            height: 60px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }

        .wave-bar {
            width: 3px;
            background: rgba(255, 255, 255, 0.6);
            margin: 0 1px;
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .conversation-log {
            max-height: 200px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 15px;
            margin-top: 20px;
            text-align: left;
            font-size: 14px;
        }

        .message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 12px;
            word-wrap: break-word;
        }

        .message.user {
            background: rgba(33, 150, 243, 0.3);
            margin-left: 20px;
        }

        .message.ai {
            background: rgba(76, 175, 80, 0.3);
            margin-right: 20px;
        }

        .session-info {
            font-size: 12px;
            opacity: 0.7;
            margin-top: 20px;
            padding: 10px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 8px;
        }

        .debug-info {
            font-size: 11px;
            opacity: 0.6;
            margin-top: 10px;
            padding: 10px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 8px;
            text-align: left;
            max-height: 100px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="logo">üéôÔ∏è</div>
        <h1 class="title">Gemini Native Audio</h1>
        <p class="subtitle">Real-time AI voice conversation</p>
        
        <div class="status" id="status">Initializing...</div>
        
        <button class="mic-button" id="micButton" disabled>
            üé§
        </button>
        
        <div class="waveform" id="waveform">
            <!-- Wave bars will be generated here -->
        </div>
        
        <div class="controls">
            <button class="control-btn" id="connectBtn" disabled>Connect</button>
            <button class="control-btn" id="disconnectBtn" disabled>Disconnect</button>
        </div>
        
        <div class="conversation-log" id="conversationLog">
            <div class="message ai">üëã Hi! Click Connect to start our native audio conversation with affective dialog!</div>
        </div>
        
        <div class="session-info" id="sessionInfo">
            Session: Loading...
        </div>
        
        <div class="debug-info" id="debugInfo">
            Debug info will appear here...
        </div>
    </div>

    <script type="module">
        class GeminiNativeAudioChat {
            constructor() {
                this.sessionToken = null;
                this.geminiClient = null;
                this.liveSession = null;
                this.isRecording = false;
                this.isConnected = false;
                this.mediaRecorder = null;
                this.audioContext = null;
                this.analyser = null;
                this.dataArray = null;
                this.animationId = null;
                this.responseQueue = [];
                this.audioChunks = [];
                
                this.initializeUI();
                this.initializeSession();
            }

            initializeUI() {
                this.statusEl = document.getElementById('status');
                this.micButton = document.getElementById('micButton');
                this.connectBtn = document.getElementById('connectBtn');
                this.disconnectBtn = document.getElementById('disconnectBtn');
                this.conversationLog = document.getElementById('conversationLog');
                this.sessionInfo = document.getElementById('sessionInfo');
                this.waveform = document.getElementById('waveform');
                this.debugInfo = document.getElementById('debugInfo');

                // Event listeners
                this.micButton.addEventListener('click', () => this.toggleRecording());
                this.connectBtn.addEventListener('click', () => this.connectToGemini());
                this.disconnectBtn.addEventListener('click', () => this.disconnect());

                // Generate wave bars
                this.generateWaveBars();
            }

            generateWaveBars() {
                this.waveform.innerHTML = '';
                for (let i = 0; i < 50; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'wave-bar';
                    bar.style.height = '10px';
                    this.waveform.appendChild(bar);
                }
            }

            addDebugInfo(message) {
                const timestamp = new Date().toLocaleTimeString();
                this.debugInfo.innerHTML += `${timestamp}: ${message}<br>`;
                this.debugInfo.scrollTop = this.debugInfo.scrollHeight;
                console.log(message);
            }

            async initializeSession() {
                try {
                    this.addDebugInfo('Starting session initialization...');
                    
                    // Get session token from URL
                    const urlParams = new URLSearchParams(window.location.search);
                    this.sessionToken = urlParams.get('session');
                    
                    if (!this.sessionToken) {
                        throw new Error('No session token provided');
                    }

                    this.addDebugInfo(`Session token: ${this.sessionToken.substring(0, 20)}...`);
                    this.updateStatus('Getting session config...');
                    
                    // Get session configuration from n8n
                    const apiUrl = `https://n8n.lomeai.com/webhook/voice-session?session=${this.sessionToken}&action=initialize`;
                    this.addDebugInfo(`Calling API: ${apiUrl}`);
                    
                    const response = await fetch(apiUrl);
                    const rawData = await response.json();
                    
                    this.addDebugInfo(`Raw response: ${JSON.stringify(rawData).substring(0, 200)}...`);
                    
                    // Handle the response format from n8n
                    let data;
                    if (Array.isArray(rawData) && rawData.length > 0) {
                        data = rawData[0];
                        this.addDebugInfo('Parsed array response');
                    } else {
                        data = rawData;
                        this.addDebugInfo('Direct response format');
                    }
                    
                    if (!data || !data.success) {
                        throw new Error(data?.error || 'Failed to initialize session');
                    }

                    this.sessionConfig = data.config;
                    this.sessionInfo.textContent = `Session: ${data.sessionId} | User: ${data.userId}`;
                    
                    this.addDebugInfo(`Model: ${this.sessionConfig.model}`);
                    this.addDebugInfo(`API Key: ${this.sessionConfig.apiKey ? 'Present' : 'Missing'}`);
                    
                    // Load Gemini SDK dynamically
                    await this.loadGeminiSDK();
                    
                    this.updateStatus('Ready to connect');
                    this.connectBtn.disabled = false;
                    
                } catch (error) {
                    this.addDebugInfo(`Session init error: ${error.message}`);
                    console.error('Session initialization failed:', error);
                    this.updateStatus('Failed to initialize session: ' + error.message, 'error');
                }
            }

            async loadGeminiSDK() {
                try {
                    this.addDebugInfo('Loading Gemini SDK...');
                    
                    // The @google/genai package may not be available via CDN
                    // Let's try multiple approaches to load the SDK
                    
                    let GoogleGenAI, Modality;
                    
                    try {
                        // Try the official package first
                        const module = await import('https://esm.run/@google/genai');
                        GoogleGenAI = module.GoogleGenAI;
                        Modality = module.Modality;
                        this.addDebugInfo('Loaded from @google/genai');
                    } catch (e1) {
                        this.addDebugInfo('Failed to load @google/genai: ' + e1.message);
                        
                        try {
                            // Try alternative CDN
                            const module = await import('https://cdn.skypack.dev/@google/genai');
                            GoogleGenAI = module.GoogleGenAI;
                            Modality = module.Modality;
                            this.addDebugInfo('Loaded from skypack');
                        } catch (e2) {
                            this.addDebugInfo('Failed to load from skypack: ' + e2.message);
                            
                            try {
                                // Try unpkg
                                const module = await import('https://unpkg.com/@google/genai/dist/index.mjs');
                                GoogleGenAI = module.GoogleGenAI;
                                Modality = module.Modality;
                                this.addDebugInfo('Loaded from unpkg');
                            } catch (e3) {
                                this.addDebugInfo('Failed to load from unpkg: ' + e3.message);
                                
                                // Last resort: explain the issue to user
                                throw new Error('Cannot load @google/genai SDK from CDN. This package may need to be installed locally or may not be available for browser use yet. The Live API might require server-side implementation.');
                            }
                        }
                    }
                    
                    if (!GoogleGenAI) {
                        throw new Error('GoogleGenAI class not found in any package');
                    }
                    
                    this.addDebugInfo('SDK loaded successfully');
                    
                    // Store the classes globally for use
                    window.GoogleGenAI = GoogleGenAI;
                    window.Modality = Modality;
                    
                    // Initialize Gemini client with API key
                    this.geminiClient = new GoogleGenAI({ apiKey: this.sessionConfig.apiKey });
                    
                    this.addDebugInfo('Gemini client initialized');
                    this.addDebugInfo(`Live API available: ${this.geminiClient.live ? 'Yes' : 'No'}`);
                    
                    if (!this.geminiClient.live) {
                        throw new Error('Live API not available in loaded SDK');
                    }
                    
                } catch (error) {
                    this.addDebugInfo(`SDK load error: ${error.message}`);
                    console.error('Failed to load Gemini SDK:', error);
                    
                    // Show helpful error message to user
                    if (error.message.includes('Cannot load @google/genai SDK')) {
                        this.addMessage('‚ö†Ô∏è The Gemini Live API SDK is not available for direct browser use. This might require a server-side proxy implementation.', 'ai');
                    }
                    
                    throw error;
                }
            }

            async connectToGemini() {
                try {
                    this.addDebugInfo('Starting Gemini connection...');
                    this.updateStatus('Connecting to Gemini...', 'connecting');
                    this.connectBtn.disabled = true;

                    // Use the native audio model from our config
                    const model = this.sessionConfig.model; // Should be 'gemini-2.5-flash-preview-native-audio-dialog'
                    
                    // Configure for native audio output with affective dialog
                    const config = {
                        responseModalities: [window.Modality ? window.Modality.AUDIO : 'AUDIO'], // Native audio output
                        enable_affective_dialog: true,  // Emotion-aware responses
                        proactivity: {
                            proactive_audio: true       // Smart response decisions
                        },
                        speech_config: {
                            voice_config: {
                                prebuilt_voice_config: {
                                    voice_name: 'Aoede'  // Use Aoede voice
                                }
                            }
                        },
                        realtime_input_config: {
                            automatic_activity_detection: {
                                disabled: false,
                                start_of_speech_sensitivity: 'START_SENSITIVITY_MEDIUM',
                                end_of_speech_sensitivity: 'END_SENSITIVITY_MEDIUM'
                            }
                        },
                        system_instruction: {
                            parts: [{
                                text: "You are a helpful AI assistant having a natural voice conversation with a user through Telegram. Be conversational, friendly, and respond naturally with appropriate emotion and tone. Keep responses concise but engaging."
                            }]
                        }
                    };

                    this.addDebugInfo(`Connecting with model: ${model}`);
                    this.addDebugInfo(`Config: ${JSON.stringify(config, null, 2).substring(0, 300)}...`);

                    // Create live session using the native audio model
                    this.liveSession = await this.geminiClient.live.connect({
                        model: model,
                        config: config,
                        callbacks: {
                            onopen: () => {
                                this.addDebugInfo('WebSocket connection opened');
                                console.log('Gemini Live API connected');
                                this.isConnected = true;
                                this.updateStatus('Connected! Click microphone to talk', 'connected');
                                this.micButton.disabled = false;
                                this.micButton.classList.add('connected');
                                this.disconnectBtn.disabled = false;
                                this.connectBtn.disabled = true;
                                this.addMessage('ü§ñ Connected! I can hear you now with native audio and affective dialog. Click the microphone to start talking!', 'ai');
                            },
                            onmessage: (message) => {
                                this.addDebugInfo(`Received message type: ${message.type || 'unknown'}`);
                                console.log('Received message:', message);
                                this.responseQueue.push(message);
                                this.handleGeminiMessage(message);
                            },
                            onerror: (error) => {
                                this.addDebugInfo(`Connection error: ${error.message}`);
                                console.error('Gemini error:', error);
                                this.updateStatus('Connection error: ' + error.message, 'error');
                                this.handleDisconnection();
                            },
                            onclose: (event) => {
                                this.addDebugInfo(`Connection closed: ${event.reason}`);
                                console.log('Connection closed:', event.reason);
                                this.updateStatus('Connection closed', 'error');
                                this.handleDisconnection();
                            }
                        }
                    });

                    this.addDebugInfo('Live session created successfully');

                } catch (error) {
                    this.addDebugInfo(`Connection failed: ${error.message}`);
                    console.error('Failed to connect to Gemini:', error);
                    this.updateStatus('Connection failed: ' + error.message, 'error');
                    this.connectBtn.disabled = false;
                }
            }

            async handleGeminiMessage(message) {
                // Handle different message types from Gemini Live API
                if (message.text) {
                    this.addMessage('ü§ñ ' + message.text, 'ai');
                    this.addDebugInfo(`Text response: ${message.text.substring(0, 50)}...`);
                }
                
                if (message.data) {
                    // Handle native audio response (24kHz PCM as per docs)
                    this.addDebugInfo(`Audio response received: ${message.data.length} bytes`);
                    await this.playAudioResponse(message.data);
                }
                
                if (message.serverContent) {
                    this.addDebugInfo('Server content received');
                    if (message.serverContent.turnComplete) {
                        this.addDebugInfo('Turn completed');
                    }
                }
            }

            async playAudioResponse(audioData) {
                try {
                    this.addDebugInfo('Playing audio response...');
                    
                    // Convert base64 audio to playable format
                    // According to docs: Audio output always uses 24kHz, 16-bit PCM
                    const binaryString = window.atob(audioData);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    // Create audio context and decode
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // For 24kHz PCM audio from Gemini
                    const sampleRate = 24000;
                    const channels = 1;
                    const audioBuffer = audioContext.createBuffer(channels, bytes.length / 2, sampleRate);
                    
                    // Convert bytes to 16-bit PCM samples
                    const channelData = audioBuffer.getChannelData(0);
                    for (let i = 0; i < channelData.length; i++) {
                        const sample = (bytes[i * 2 + 1] << 8) | bytes[i * 2];
                        channelData[i] = sample < 32768 ? sample / 32768 : (sample - 65536) / 32768;
                    }
                    
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                    
                    this.addMessage('üîä [Playing native audio response]', 'ai');
                    this.addDebugInfo('Audio playback started');
                    
                } catch (error) {
                    this.addDebugInfo(`Audio playback error: ${error.message}`);
                    console.error('Error playing audio:', error);
                    this.addMessage('üîä [Received audio response - playback failed]', 'ai');
                }
            }

            async toggleRecording() {
                if (!this.isConnected) {
                    this.updateStatus('Please connect first', 'error');
                    return;
                }

                if (this.isRecording) {
                    this.stopRecording();
                } else {
                    await this.startRecording();
                }
            }

            async startRecording() {
                try {
                    this.addDebugInfo('Starting audio recording...');
                    
                    // Request microphone access with correct format for Gemini
                    // Input audio is natively 16kHz but API will resample as needed
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            channelCount: 1,
                            sampleRate: 16000,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        } 
                    });

                    this.addDebugInfo('Microphone access granted');

                    // Set up audio context for visualization
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);

                    this.analyser.fftSize = 256;
                    const bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(bufferLength);

                    // Start continuous recording for real-time streaming
                    this.stream = stream;
                    this.isRecording = true;
                    
                    this.micButton.classList.add('recording');
                    this.micButton.innerHTML = '‚èπÔ∏è';
                    this.updateStatus('Recording... Click to stop', 'recording');
                    
                    this.startWaveAnimation();
                    this.addMessage('üé§ Recording started - streaming to Gemini...', 'user');
                    
                    // Start streaming audio to Gemini in real-time
                    this.startAudioStreaming();

                } catch (error) {
                    this.addDebugInfo(`Recording start error: ${error.message}`);
                    console.error('Failed to start recording:', error);
                    this.updateStatus('Microphone access denied: ' + error.message, 'error');
                }
            }

            async startAudioStreaming() {
                try {
                    // Create a media recorder for real-time streaming
                    this.mediaRecorder = new MediaRecorder(this.stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    this.audioChunks = [];
                    
                    this.mediaRecorder.ondataavailable = async (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                            // Send audio chunk to Gemini immediately
                            await this.sendAudioChunkToGemini(event.data);
                        }
                    };
                    
                    // Start recording with small time slices for real-time streaming
                    this.mediaRecorder.start(1000); // 1 second chunks
                    
                    this.addDebugInfo('Audio streaming started');
                    
                } catch (error) {
                    this.addDebugInfo(`Audio streaming error: ${error.message}`);
                    console.error('Failed to start audio streaming:', error);
                }
            }

            async sendAudioChunkToGemini(audioChunk) {
                try {
                    // Convert audio chunk to the format expected by Gemini
                    const audioBuffer = await audioChunk.arrayBuffer();
                    const base64Audio = this.arrayBufferToBase64(audioBuffer);
                    
                    this.addDebugInfo(`Sending audio chunk: ${audioBuffer.byteLength} bytes`);
                    
                    // Send audio to Gemini Live API using sendRealtimeInput
                    await this.liveSession.sendRealtimeInput({
                        audio: {
                            data: base64Audio,
                            mimeType: "audio/pcm;rate=16000"
                        }
                    });
                    
                } catch (error) {
                    this.addDebugInfo(`Audio send error: ${error.message}`);
                    console.error('Failed to send audio chunk:', error);
                }
            }

            stopRecording() {
                if (this.isRecording) {
                    this.addDebugInfo('Stopping recording...');
                    
                    this.isRecording = false;
                    
                    if (this.mediaRecorder) {
                        this.mediaRecorder.stop();
                    }
                    
                    if (this.stream) {
                        this.stream.getTracks().forEach(track => track.stop());
                    }
                    
                    this.micButton.classList.remove('recording');
                    this.micButton.innerHTML = 'üé§';
                    this.updateStatus('Connected! Click microphone to talk', 'connected');
                    
                    this.stopWaveAnimation();
                    this.addMessage('üé§ Recording stopped', 'user');
                }
            }

            arrayBufferToBase64(buffer) {
                const bytes = new Uint8Array(buffer);
                let binary = '';
                for (let i = 0; i < bytes.byteLength; i++) {
                    binary += String.fromCharCode(bytes[i]);
                }
                return window.btoa(binary);
            }

            startWaveAnimation() {
                const animate = () => {
                    if (!this.isRecording) return;
                    
                    this.analyser.getByteFrequencyData(this.dataArray);
                    
                    const bars = this.waveform.querySelectorAll('.wave-bar');
                    bars.forEach((bar, index) => {
                        const value = this.dataArray[index] || 0;
                        const height = Math.max(5, (value / 255) * 50);
                        bar.style.height = height + 'px';
                    });
                    
                    this.animationId = requestAnimationFrame(animate);
                };
                animate();
            }

            stopWaveAnimation() {
                if (this.animationId) {
                    cancelAnimationFrame(this.animationId);
                    this.animationId = null;
                }
                
                const bars = this.waveform.querySelectorAll('.wave-bar');
                bars.forEach(bar => {
                    bar.style.height = '10px';
                });
            }

            disconnect() {
                this.addDebugInfo('Disconnecting...');
                if (this.liveSession) {
                    this.liveSession.close();
                }
                this.handleDisconnection();
            }

            handleDisconnection() {
                this.isConnected = false;
                this.isRecording = false;
                
                this.micButton.disabled = true;
                this.micButton.classList.remove('connected', 'recording');
                this.micButton.innerHTML = 'üé§';
                
                this.connectBtn.disabled = false;
                this.disconnectBtn.disabled = true;
                
                this.stopWaveAnimation();
                this.updateStatus('Disconnected. Click Connect to start again');
                
                if (this.stream) {
                    this.stream.getTracks().forEach(track => track.stop());
                }
            }

            updateStatus(message, type = '') {
                this.statusEl.textContent = message;
                this.statusEl.className = 'status ' + type;
            }

            addMessage(text, sender) {
                const messageEl = document.createElement('div');
                messageEl.className = `message ${sender}`;
                messageEl.textContent = text;
                
                this.conversationLog.appendChild(messageEl);
                this.conversationLog.scrollTop = this.conversationLog.scrollHeight;
            }
        }

        // Initialize the app when the page loads
        window.addEventListener('load', () => {
            new GeminiNativeAudioChat();
        });

        // Telegram WebApp specific code
        if (window.Telegram?.WebApp) {
            window.Telegram.WebApp.ready();
            window.Telegram.WebApp.expand();
        }
    </script>
</body>
</html>
